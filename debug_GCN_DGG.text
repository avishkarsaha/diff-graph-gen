220730_cora_gcndgg_debug
	- overview: cora average node degree is 4.9, the learned k is converging to around
		   around 3.3. the 'on edge values' mean difference (i.e. elementwise
		   difference between ground truth edge weight of 1 and predicted
		   edge probability) is 0.25, meaning the edge probabilities have a mean
		   of 0.75.
	- thoughts:
		- edge encoder should give values closer to 1? maybe we need to return a hard adj
		- k value is too low
	- things to try:
		- check errors with edge encoder by fixing k and testing for a range of k values
		- use edge encoder to get edge probabilities, and then use fixed k and return 
		  an undifferentiable adj matrix (i.e basically selecting the top k from the
		  original adj matrix using their input node features) 
		- want to find out if edge encoder is wrong - is it embedding nodes closer together
		  when they shouldnt be? 

220801_cora_gcndgg_step0 series
	- what: returning edge_probs at step 0
	- effect: 
		- u-v-dist as edge encoder leads to rapid overfitting and decrease
		  in test accuracy after a certain point
		- returning a hard adj mat totally breaks and doesn't work at step 0
		- u-v-deg as edge encoder gets best acc (81.4%) and doesnt decrease
		  like u-v-dist - this only works really because it can push
		  the likelihood of each existing edge in the input graph to 1
		- edge_conv as edge encoder gives low acc (65%)
		- A_uv gives similar results as u-v-dist
		- u-v-deg-dist (u-v-deg with u-v-dist) decreases acc to 65%
